{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from numpy import *\n",
    "# import cv2 as cv\n",
    "from time import sleep\n",
    "import os\n",
    "import errno\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(folder):\n",
    "    x_data_temp = []\n",
    "    y_data_temp = []\n",
    "    x_test_data_temp = []\n",
    "    y_test_data_temp = []\n",
    "    \n",
    "    for file in os.listdir(folder):\n",
    "        if file.endswith(\".meta\") or file.endswith(\".html\"):\n",
    "            print(\"Ignoring html and meta files\")\n",
    "        elif \"test_batch\" in file:\n",
    "            # test data file detected. we are gonna load it separately\n",
    "            test_data_temp = unpickle(folder + \"/\" + file)\n",
    "            x_test_data_temp.append(test_data_temp[b'data'])\n",
    "            y_test_data_temp.append(test_data_temp[b'labels'])\n",
    "        else:\n",
    "            temp_data = unpickle(folder + \"/\" + file)\n",
    "            x_data_temp.append(temp_data[b'data'])\n",
    "            y_data_temp.append(temp_data[b'labels'])\n",
    "    x_data = array(x_data_temp)\n",
    "    y_data = array(y_data_temp)\n",
    "    x_test_data = array(x_test_data_temp)\n",
    "    y_test_data = array(y_test_data_temp)\n",
    "    return [x_data, y_data, x_test_data, y_test_data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sonalisreedhar/Documents/DIP/HW5\n"
     ]
    }
   ],
   "source": [
    "cd /Users/sonalisreedhar/Documents/DIP/HW5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignoring html and meta files\n",
      "Ignoring html and meta files\n"
     ]
    }
   ],
   "source": [
    "X_train_temp, y_train_temp, X_test_temp, y_test_temp = read_data(\"cifar-10-batches-py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3072) 2 <class 'numpy.ndarray'>\n",
      "(50000,) 1 <class 'numpy.ndarray'>\n",
      "(10000, 3072) 2 <class 'numpy.ndarray'>\n",
      "(10000,) 1 <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "X_train_temp = X_train_temp.reshape(X_train_temp.shape[0] * X_train_temp.shape[1], X_train_temp.shape[2])\n",
    "y_train_temp = y_train_temp.reshape(y_train_temp.shape[0] * y_train_temp.shape[1])\n",
    "\n",
    "# Similarly for X_test_temp and y_test_data\n",
    "\n",
    "X_test_temp = X_test_temp.reshape(X_test_temp.shape[0] * X_test_temp.shape[1], X_test_temp.shape[2])\n",
    "y_test_temp = y_test_temp.reshape(y_test_temp.shape[0] * y_test_temp.shape[1])\n",
    "\n",
    "print(X_train_temp.shape, X_train_temp.ndim, type(X_train_temp))\n",
    "print(y_train_temp.shape, y_train_temp.ndim, type(y_train_temp))\n",
    "\n",
    "print(X_test_temp.shape, X_test_temp.ndim, type(X_test_temp))\n",
    "print(y_test_temp.shape, y_test_temp.ndim, type(y_test_temp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 3072) 2 <class 'numpy.ndarray'>\n",
      "(10000,) 1 <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(X_test_temp.shape, X_test_temp.ndim, type(X_test_temp))\n",
    "print(y_test_temp.shape, y_test_temp.ndim, type(y_test_temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = shuffle(X_train_temp, y_train_temp, random_state=4)\n",
    "X_test, y_test = shuffle(X_test_temp, y_test_temp, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0],  32, 32,3)\n",
    "y_train = np_utils.to_categorical(y_train, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = X_val.reshape(X_val.shape[0],  32, 32,3)\n",
    "y_val = np_utils.to_categorical(y_val, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.reshape(X_test.shape[0],  32, 32,3)\n",
    "y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 32, 32, 3) (40000, 10)\n",
      "(10000, 32, 32, 3) (10000, 10)\n",
      "(10000, 32, 32, 3) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_val = X_val.astype('float32')\n",
    "X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train /= 255\n",
    "X_val /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "cnnModel = Sequential()\n",
    "cnnModel.add(Conv2D(6, (5, 5), padding='valid', activation = 'relu', kernel_initializer='he_normal', input_shape=(32,32,3)))\n",
    "cnnModel.add(MaxPooling2D((2, 2), strides=(1, 1)))\n",
    "cnnModel.add(Conv2D(16, (5, 5), padding='valid', activation = 'relu', kernel_initializer='he_normal'))\n",
    "cnnModel.add(MaxPooling2D((2, 2), strides=(1, 1)))\n",
    "cnnModel.add(Flatten())\n",
    "cnnModel.add(Dense(120, activation = 'relu', kernel_initializer='he_normal'))\n",
    "cnnModel.add(Dense(84, activation = 'relu', kernel_initializer='he_normal'))\n",
    "cnnModel.add(Dense(10, activation = 'softmax', kernel_initializer='he_normal'))\n",
    "sgd = optimizers.SGD(lr=.1, momentum=0.9, nesterov=True)\n",
    "cnnModel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mport keras\n",
    "from keras import optimizers\n",
    "# from keras.datasets import cifar10\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Conv2D, Dense, Flatten, MaxPooling2D\n",
    "from keras.callbacks import LearningRateScheduler, TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import logging\n",
    "logging.getLogger('tensorflow').setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "40000/40000 [==============================] - 90s 2ms/step - loss: 0.2564 - acc: 0.9094 - val_loss: 3.1988 - val_acc: 0.4828\n",
      "Epoch 2/50\n",
      "40000/40000 [==============================] - 87s 2ms/step - loss: 0.2333 - acc: 0.9188 - val_loss: 3.2417 - val_acc: 0.4762\n",
      "Epoch 3/50\n",
      "40000/40000 [==============================] - 88s 2ms/step - loss: 0.2197 - acc: 0.9223 - val_loss: 3.5468 - val_acc: 0.4690\n",
      "Epoch 4/50\n",
      "40000/40000 [==============================] - 88s 2ms/step - loss: 0.2181 - acc: 0.9231 - val_loss: 3.4919 - val_acc: 0.4569\n",
      "Epoch 5/50\n",
      "40000/40000 [==============================] - 91s 2ms/step - loss: 0.1986 - acc: 0.9326 - val_loss: 3.7792 - val_acc: 0.4623\n",
      "Epoch 6/50\n",
      "40000/40000 [==============================] - 87s 2ms/step - loss: 0.2028 - acc: 0.9288 - val_loss: 3.6997 - val_acc: 0.4627\n",
      "Epoch 7/50\n",
      "40000/40000 [==============================] - 87s 2ms/step - loss: 0.1856 - acc: 0.9365 - val_loss: 3.8831 - val_acc: 0.4717\n",
      "Epoch 8/50\n",
      "40000/40000 [==============================] - 88s 2ms/step - loss: 0.1795 - acc: 0.9379 - val_loss: 3.9754 - val_acc: 0.4743\n",
      "Epoch 9/50\n",
      "40000/40000 [==============================] - 89s 2ms/step - loss: 0.1775 - acc: 0.9395 - val_loss: 4.0462 - val_acc: 0.4700\n",
      "Epoch 10/50\n",
      "40000/40000 [==============================] - 90s 2ms/step - loss: 0.1715 - acc: 0.9413 - val_loss: 4.0434 - val_acc: 0.4729\n",
      "Epoch 11/50\n",
      "40000/40000 [==============================] - 89s 2ms/step - loss: 0.1644 - acc: 0.9444 - val_loss: 4.0411 - val_acc: 0.4697\n",
      "Epoch 12/50\n",
      "40000/40000 [==============================] - 89s 2ms/step - loss: 0.1664 - acc: 0.9425 - val_loss: 4.1517 - val_acc: 0.4658\n",
      "Epoch 13/50\n",
      "40000/40000 [==============================] - 89s 2ms/step - loss: 0.1575 - acc: 0.9456 - val_loss: 4.1668 - val_acc: 0.4746\n",
      "Epoch 14/50\n",
      "40000/40000 [==============================] - 89s 2ms/step - loss: 0.1594 - acc: 0.9456 - val_loss: 4.1194 - val_acc: 0.4611\n",
      "Epoch 15/50\n",
      "40000/40000 [==============================] - 90s 2ms/step - loss: 0.1504 - acc: 0.9493 - val_loss: 4.1108 - val_acc: 0.4624\n",
      "Epoch 16/50\n",
      "40000/40000 [==============================] - 90s 2ms/step - loss: 0.1493 - acc: 0.9503 - val_loss: 4.4064 - val_acc: 0.4568\n",
      "Epoch 17/50\n",
      "40000/40000 [==============================] - 90s 2ms/step - loss: 0.1379 - acc: 0.9537 - val_loss: 4.3922 - val_acc: 0.4645\n",
      "Epoch 18/50\n",
      "40000/40000 [==============================] - 89s 2ms/step - loss: 0.1470 - acc: 0.9501 - val_loss: 4.4388 - val_acc: 0.4634\n",
      "Epoch 19/50\n",
      "40000/40000 [==============================] - 90s 2ms/step - loss: 0.1409 - acc: 0.9528 - val_loss: 4.6074 - val_acc: 0.4597\n",
      "Epoch 20/50\n",
      "40000/40000 [==============================] - 92s 2ms/step - loss: 0.1560 - acc: 0.9489 - val_loss: 4.4230 - val_acc: 0.4661\n",
      "Epoch 21/50\n",
      "40000/40000 [==============================] - 90s 2ms/step - loss: 0.1202 - acc: 0.9590 - val_loss: 4.4620 - val_acc: 0.4638\n",
      "Epoch 22/50\n",
      "40000/40000 [==============================] - 89s 2ms/step - loss: 0.1371 - acc: 0.9544 - val_loss: 4.4455 - val_acc: 0.4584\n",
      "Epoch 23/50\n",
      "40000/40000 [==============================] - 90s 2ms/step - loss: 0.1174 - acc: 0.9603 - val_loss: 4.5693 - val_acc: 0.4701\n",
      "Epoch 24/50\n",
      "40000/40000 [==============================] - 90s 2ms/step - loss: 0.1195 - acc: 0.9606 - val_loss: 4.6414 - val_acc: 0.4655\n",
      "Epoch 25/50\n",
      "40000/40000 [==============================] - 88s 2ms/step - loss: 0.1423 - acc: 0.9550 - val_loss: 4.5741 - val_acc: 0.4571\n",
      "Epoch 26/50\n",
      "40000/40000 [==============================] - 87s 2ms/step - loss: 0.1228 - acc: 0.9594 - val_loss: 4.7199 - val_acc: 0.4659\n",
      "Epoch 27/50\n",
      "40000/40000 [==============================] - 87s 2ms/step - loss: 0.1230 - acc: 0.9590 - val_loss: 4.6502 - val_acc: 0.4684\n",
      "Epoch 28/50\n",
      "40000/40000 [==============================] - 87s 2ms/step - loss: 0.1251 - acc: 0.9584 - val_loss: 4.6224 - val_acc: 0.4575\n",
      "Epoch 29/50\n",
      "40000/40000 [==============================] - 90s 2ms/step - loss: 0.1172 - acc: 0.9610 - val_loss: 4.7976 - val_acc: 0.4656\n",
      "Epoch 30/50\n",
      "40000/40000 [==============================] - 101s 3ms/step - loss: 0.1148 - acc: 0.9617 - val_loss: 4.8271 - val_acc: 0.4688\n",
      "Epoch 31/50\n",
      "40000/40000 [==============================] - 96s 2ms/step - loss: 0.1092 - acc: 0.9642 - val_loss: 4.6689 - val_acc: 0.4604\n",
      "Epoch 32/50\n",
      "40000/40000 [==============================] - 96s 2ms/step - loss: 0.1191 - acc: 0.9618 - val_loss: 4.8340 - val_acc: 0.4635\n",
      "Epoch 33/50\n",
      "40000/40000 [==============================] - 96s 2ms/step - loss: 0.1234 - acc: 0.9601 - val_loss: 4.8062 - val_acc: 0.4577\n",
      "Epoch 34/50\n",
      "40000/40000 [==============================] - 96s 2ms/step - loss: 0.1061 - acc: 0.9660 - val_loss: 4.5997 - val_acc: 0.4561\n",
      "Epoch 35/50\n",
      "40000/40000 [==============================] - 95s 2ms/step - loss: 0.1071 - acc: 0.9664 - val_loss: 4.8559 - val_acc: 0.4573\n",
      "Epoch 36/50\n",
      "40000/40000 [==============================] - 89s 2ms/step - loss: 0.1001 - acc: 0.9673 - val_loss: 4.7606 - val_acc: 0.4567\n",
      "Epoch 37/50\n",
      "40000/40000 [==============================] - 89s 2ms/step - loss: 0.1164 - acc: 0.9624 - val_loss: 4.8804 - val_acc: 0.4589\n",
      "Epoch 38/50\n",
      "40000/40000 [==============================] - 89s 2ms/step - loss: 0.0974 - acc: 0.9685 - val_loss: 5.0884 - val_acc: 0.4660\n",
      "Epoch 39/50\n",
      "40000/40000 [==============================] - 89s 2ms/step - loss: 0.1024 - acc: 0.9669 - val_loss: 4.8972 - val_acc: 0.4620\n",
      "Epoch 40/50\n",
      "40000/40000 [==============================] - 89s 2ms/step - loss: 0.1116 - acc: 0.9638 - val_loss: 4.9329 - val_acc: 0.4696\n",
      "Epoch 41/50\n",
      "40000/40000 [==============================] - 91s 2ms/step - loss: 0.0901 - acc: 0.9694 - val_loss: 5.2092 - val_acc: 0.4661\n",
      "Epoch 42/50\n",
      "40000/40000 [==============================] - 90s 2ms/step - loss: 0.1057 - acc: 0.9663 - val_loss: 5.0000 - val_acc: 0.4592\n",
      "Epoch 43/50\n",
      "40000/40000 [==============================] - 90s 2ms/step - loss: 0.0924 - acc: 0.9696 - val_loss: 5.1604 - val_acc: 0.4513\n",
      "Epoch 44/50\n",
      "40000/40000 [==============================] - 89s 2ms/step - loss: 0.0958 - acc: 0.9700 - val_loss: 5.1136 - val_acc: 0.4514\n",
      "Epoch 45/50\n",
      "40000/40000 [==============================] - 90s 2ms/step - loss: 0.1094 - acc: 0.9653 - val_loss: 5.1368 - val_acc: 0.4499\n",
      "Epoch 46/50\n",
      "40000/40000 [==============================] - 90s 2ms/step - loss: 0.0977 - acc: 0.9690 - val_loss: 5.2388 - val_acc: 0.4654\n",
      "Epoch 47/50\n",
      "40000/40000 [==============================] - 91s 2ms/step - loss: 0.0928 - acc: 0.9702 - val_loss: 5.0863 - val_acc: 0.4668\n",
      "Epoch 48/50\n",
      "40000/40000 [==============================] - 91s 2ms/step - loss: 0.0986 - acc: 0.9689 - val_loss: 5.0277 - val_acc: 0.4612\n",
      "Epoch 49/50\n",
      "40000/40000 [==============================] - 91s 2ms/step - loss: 0.0879 - acc: 0.9712 - val_loss: 5.1339 - val_acc: 0.4648\n",
      "Epoch 50/50\n",
      "40000/40000 [==============================] - 91s 2ms/step - loss: 0.0944 - acc: 0.9704 - val_loss: 4.9773 - val_acc: 0.4491\n"
     ]
    }
   ],
   "source": [
    "history = cnnModel.fit(X_train, y_train, batch_size=32, epochs=50,\n",
    "                    verbose=1, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 8s 757us/step\n",
      "Test Score : 4.977294649505615\n",
      "Test accuracy:  0.4491\n",
      "[5 0 7 6 9 2 3 7 8 0 5 6 9 3 4 0 3 0 2 6 5 4 1 3 3 4 0 3 7 5 1 1 5 4 6 8 9\n",
      " 7 9 7 6 7 9 1 2 1 0 7 5]\n",
      "[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "score = cnnModel.evaluate(X_test, y_test, verbose=1)\n",
    "print(\"Test Score :\", score[0])\n",
    "print(\"Test accuracy: \", score[1])\n",
    "print(cnnModel.predict_classes(X_test[1:50]))\n",
    "print(y_test[1:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set callback\n",
    "tb_cb = TensorBoard(log_dir='./lenet', histogram_freq=0)\n",
    "change_lr = LearningRateScheduler(scheduler)\n",
    "cbks = [change_lr,tb_cb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected conv2d_3_input to have shape (32, 32, 3) but got array with shape (3, 32, 32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-cda0dde6ae45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m              \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcbks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m              \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m              shuffle=True)\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    136\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    139\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected conv2d_3_input to have shape (32, 32, 3) but got array with shape (3, 32, 32)"
     ]
    }
   ],
   "source": [
    " # start train\n",
    "classifier.fit(X_train, y_train,\n",
    "              batch_size=128,\n",
    "              epochs=200,\n",
    "              callbacks=cbks,\n",
    "              validation_data=(X_val, y_val),\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
